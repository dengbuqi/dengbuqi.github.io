<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Combat Effectiveness(CE) Detection</title>
    <url>/2023/03/23/Combat-Effectiveness-CE-Detection/</url>
    <content><![CDATA[<h1 id="Combat-Effectiveness-Detection-using-YOLOv8-and-Tensorflow-js"><a href="#Combat-Effectiveness-Detection-using-YOLOv8-and-Tensorflow-js" class="headerlink" title="Combat Effectiveness Detection using YOLOv8 and Tensorflow.js"></a>Combat Effectiveness Detection using YOLOv8 and Tensorflow.js</h1><p align="center">
  <img src="/images/ce.jpg" />
</p>

<p><img src="https://img.shields.io/badge/Made%20with-%F0%9F%96%A4-white" alt="love"><br><img src="https://img.shields.io/badge/tensorflow.js-white?logo=tensorflow" alt="tensorflow.js"></p>
<hr>
<p>Combat Effectveness Detection application right in your browser. Serving YOLOv8 in browser using tensorflow.js<br>with <code>webgl</code> backend.</p>
<h2 id="DEMO"><a href="#DEMO" class="headerlink" title="DEMO"></a>DEMO</h2><p><a href="https://dengbuqi.github.io/Combat-Effectiveness-Detection_yolov8-tfjs/">Check it!</a></p>
<ul>
<li><a href="https://dengbuqi.github.io/Combat-Effectiveness-Detection_yolov8-tfjs/">https://dengbuqi.github.io/Combat-Effectiveness-Detection_yolov8-tfjs/</a></li>
</ul>
<p><strong>Setup</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/dengbuqi/Combat-Effectiveness-Detection_yolov8-tfjs</span><br><span class="line"><span class="built_in">cd</span> Combat-Effectiveness-Detection_yolov8-tfjs</span><br><span class="line">yarn install <span class="comment">#Install dependencies</span></span><br></pre></td></tr></table></figure>

<p><strong>Scripts</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yarn start <span class="comment"># Start dev server</span></span><br><span class="line">yarn build <span class="comment"># Build for productions</span></span><br></pre></td></tr></table></figure>

<h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><p>YOLOv8n model converted to tensorflow.js.</p>
<figure class="highlight ada"><table><tr><td class="code"><pre><span class="line">used model : <span class="type">yolov8n</span></span><br><span class="line">size       : 13 <span class="type">Mb</span></span><br></pre></td></tr></table></figure>

<p><strong>Use another model</strong></p>
<p>Use another YOLOv8 model.</p>
<ol>
<li><p>Export YOLOv8 model to tfjs format. Read more on the <a href="https://docs.ultralytics.com/tasks/detection/#export">official documentation</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> ultralytics <span class="keyword">import</span> YOLO</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load a model</span></span><br><span class="line">model = YOLO(<span class="string">&quot;yolov8n.pt&quot;</span>)  <span class="comment"># load an official model</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Export the model</span></span><br><span class="line">model.export(<span class="built_in">format</span>=<span class="string">&quot;tfjs&quot;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>Copy <code>yolov8*_web_model</code> to <code>./public</code></p>
</li>
<li><p>Update <code>modelName</code> in <code>App.jsx</code> to new model name</p>
<figure class="highlight jsx"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="comment">// model configs</span></span><br><span class="line"><span class="keyword">const</span> modelName = <span class="string">&quot;yolov8*&quot;</span>; <span class="comment">// change to new model name</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure></li>
<li><p>Done! 😊</p>
</li>
</ol>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://github.com/ultralytics/ultralytics">https://github.com/ultralytics/ultralytics</a></li>
<li><a href="https://github.com/Hyuto/yolov8-onnxruntime-web">https://github.com/Hyuto/yolov8-onnxruntime-web</a></li>
<li><a href="https://github.com/Hyuto/yolov8-tfjs">https://github.com/Hyuto/yolov8-tfjs</a></li>
</ul>
]]></content>
      <tags>
        <tag>Project</tag>
      </tags>
  </entry>
  <entry>
    <title>Heartbeat-Estimation</title>
    <url>/2023/03/23/Heartbeat-Estimation/</url>
    <content><![CDATA[<h1 id="heartbeat-js-FaceAPI-heart-pulse-rate-monitoring"><a href="#heartbeat-js-FaceAPI-heart-pulse-rate-monitoring" class="headerlink" title="heartbeat-js + FaceAPI heart pulse rate monitoring"></a>heartbeat-js + FaceAPI heart pulse rate monitoring</h1><p>This project combines the <a href="https://github.com/prouast/heartbeat-js">heartbeat-js</a> and <a href="https://github.com/justadudewhohacks/face-api.js/">FaceAPI</a><br>By detecting the human face using FaceAPI, we can estimate the heart pulse rate using rPPG method implemented by hearbeat-js project.</p>
<p align="center">
  <img src="/images/heartbeat.jpg" />
</p>

<h1 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h1><p>Check the demo <a href="https://dengbuqi.github.io/heartbeat-js-FaceAPI/">here~</a></p>
]]></content>
      <tags>
        <tag>Project</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2021/02/25/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>label-studio-ml-backend&#39;s segment_anything_model example bug fix: previous annotation disappearing after making new one</title>
    <url>/2023/09/10/label-studio-ml-backend-s-segment-anything-model-example-bug-fix-previous-annotation-disappearing-after-making-new-one/</url>
    <content><![CDATA[<h1 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h1><p>When I try to use <a href="https://github.com/HumanSignal/label-studio-ml-backend/tree/b2c31d34c0414befde3d0d067588617e062ef443/label_studio_ml/examples/segment_anything_model">Interactive Annotation in Label Studio with Segment Anything Model</a> Commits version: b2c31d3. I meet a problem, previous annotation is disappeared after making new annotation.(Latest version is fixed this problem[<a href="https://github.com/HumanSignal/label-studio-ml-backend/blob/master/label_studio_ml/examples/segment_anything_model/model.py">link</a>])</p>
<h1 id="Fix"><a href="#Fix" class="headerlink" title="Fix"></a>Fix</h1><p>To fix this problem, we need to modify the label-studio-ml-backend/label_studio_ml/examples/segment_anything_model/segment_anything_model.py file.<br>change the method to generate result id.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;</span>.join(random.SystemRandom().choice(string.ascii_uppercase + string.ascii_lowercase + string.digits))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>to</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> uuid <span class="keyword">import</span> uuid4</span><br><span class="line"><span class="built_in">str</span>(uuid4())[:<span class="number">4</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>Problem</tag>
      </tags>
  </entry>
  <entry>
    <title>My rethink about Image generation and recognition</title>
    <url>/2024/03/12/My-rethink-about-Image-generation-and-recognition/</url>
    <content><![CDATA[<h1 id="My-rethink-about-Image-generation-and-recognition"><a href="#My-rethink-about-Image-generation-and-recognition" class="headerlink" title="My rethink about Image generation and recognition"></a>My rethink about Image generation and recognition</h1><p>英文部分是Notion机器翻译</p>
<p>人类的大脑是图像生成最利害的机器，虽然我们无法直接向外表现出来，但是我们可以在大脑中想象出千奇百怪的东西，甚至在我们的梦境中，我们可以完全畅游在自由想像的世界。</p>
<p>The human brain is the most potent image generation machine. Although we can’t express it directly, we can imagine all sorts of things in our brains. Even in our dreams, we can fully roam the world of free imagination.</p>
<p>但是，我们人类是如何在脑中生成这些东西的呢？在我的理解中，纵使我们可以想象出任何东西，但是这个“任何东西”，很难超过我们的认知范围，即我们常说的想象的局限性。</p>
<p>But how do we humans generate these things in our minds? In my understanding, though we can imagine anything, this “anything” is hard to exceed our cognitive range, which is often referred to as the limitation of imagination.</p>
<p>我认为我们拥有这种局限性的原因是因为我们需要先<strong>观察</strong>已有的事物，然后<strong>抽象</strong>和<strong>思考</strong>这个事物的特征，才能<strong>想象</strong>出基于这个事物部分特征的其他事物。</p>
<p>I believe we have this limitation because we need to <strong>observe</strong> existing things first, then <strong>abstract</strong> and <strong>think</strong> about the features of this thing, in order to <strong>imagine</strong> other things based on some features of this thing.</p>
<p>因此，如果我们遵从人类的思考方式创建AI模型的话，我假设模型分为3部分： 观察，想象和思考。</p>
<p>Therefore, if we create AI models following human thinking, I assume the model is divided into three parts: observation, imagination, and thinking.</p>
<p><img src="/images/humangen.drawio.png" alt="humangen.drawio.png"></p>
<p>上图就是我认为的一个人类大脑的思维逻辑，或者说是一种图像生成的AI模型的结构，该结构有点类似于GAN(Generative Adversarial Network)模型。</p>
<p>The above figure is what I think is the logic of human brain thinking, or the structure of an image generation AI model, which is somewhat similar to the GAN (Generative Adversarial Network) model.</p>
<p><strong>Observation</strong>: 我们将会观察真实图片，学习并提取真实图片的隐藏特征值(Hidden Feature)。</p>
<p><strong>Observation</strong>: We will observe real images, learn and extract the hidden features of real images.</p>
<p><strong>Hidden Feature</strong>: 观察到的特征值会被应用于两个方面，一方面是用于思考，一方面是用于生成图片。</p>
<p><strong>Hidden Feature</strong>: The observed features will be applied in two ways, one for thinking and one for generating images.</p>
<p><strong>Imagination</strong>: 我们通过总结到的Hidden Feature，可以试图生成一张新的图片，这张图片和原图Real image很相似，但是又不同，目的是为了生成一张能够让observation提取到和Real image相似特征的图片。</p>
<p><strong>Imagination</strong>: We can try to generate a new image through the summarized Hidden Feature. This image is similar to the original Real image, but different. The purpose is to generate an image that allows the observation to extract features similar to the Real image.</p>
<p>让我们重新回到我们人类的思考学习方式上，当我们牙牙学语时候，假设我们认识“车”这个单词，老师会给我们一张车的图片卡，然后反复教我们这个东西是“车”。当我们记住了这张图片和与之对应的单词“车”之后，神奇的一幕发生了，即便我们看到了另一个模样的车之后，我们仍然能够“猜”出这是车！而这样神奇的能力我认为可以归因于人类想象力。因为人类在看到“车”的图片卡之后，我们不但是学习了车这个图片的特征，还学习到了很多抽象的特征，比如车有四个轮子，有方向盘等等，并基于这些抽象特征，天马行空的想象出了不同的车，而这些想象出来的车的样子，也有利于我们去识别真正现实中的车。在通过N次的对真实图片和想象图片的观察之后，我们便能思考“车”是什么，同是也具备了想象车的样子的模型。如下图：</p>
<p>Let’s return to our human thinking learning mode. When we were babbling, suppose we knew the word “car”, the teacher would give us a picture card of a car, and repeatedly teach us that this thing is a “car”. After we remembered this picture and the corresponding word “car”, a miraculous scene happened. Even if we saw another car, we could still “guess” it was a car! I attribute such magical ability to human imagination. Because after seeing the picture card of the “car”, we not only learned the features of the car picture, but also learned many abstract features, such as the car has four wheels, a steering wheel, etc., and based on these abstract features, the sky-horse-like imagination came out. Different cars, and the appearance of these imagined cars, are also conducive to our identification of real cars in reality. After observing the real image and the imagined image for N times, we can think about what a “car” is, and also have a model that imagines the appearance of a car. As below:</p>
<p><img src="/images/baby_learn.drawio.png" alt="baby_learn.drawio.png"></p>
<p><strong>Thinking</strong>: 对于特征的思考，我们大致需要思考两个方面的问题：</p>
<p>图片是真的还是想象出来的？</p>
<p>一个真假二分类问题</p>
<p>图像描述的是什么？</p>
<p>一个NLP描述问题</p>
<p><strong>Thinking</strong>: For thinking about features, we generally need to think about two aspects:</p>
<p>Is the picture real or imagined?</p>
<p>A true or false binary classification problem</p>
<p>What does the image describe?</p>
<p>An NLP description problem</p>
<p>因此，基于这一套思维逻辑，我们或许能够制作一个one-shot或者few-shot的模型，通过反复观测(Observation)和想象(Imagination)同一张图片并对他们进行思考，我们或许能生三个模型：encoder，generator,和thinker三个模型。如下图：</p>
<p>Therefore, based on this set of thinking logic, we may be able to make a one-shot or few-shot model, through repeated Observation and Imagination of the same picture and thinking about them, we may be able to generate three models: encoder, generator, and thinker. As below:</p>
<p><img src="/images/aigen.drawio.png" alt="aigen.drawio.png"></p>
<p>Loss 的设计，当我们设计loss函数的时候，主要是帧对在Thinker模块的输出，Real和Fake和对应的NLP描述均可以设计对应的距离loss函数。</p>
<p>When designing the Loss function, it is mainly designed for the output of the Thinker module, both Real and Fake and the corresponding NLP description can design the corresponding distance loss function.</p>
<p>另外，我们还可以设计一个prompt编码模块，给我们的想象力加一点提示hint，从而更好的控制generator生成的内容。</p>
<p>Additionally, we can design a prompt encoding module to add a hint to our imagination, thereby better controlling the content generated by the generator.</p>
<p><img src="/images/aigen_with_prompt.drawio.png" alt="aigen_with_prompt.drawio.png"></p>
<p>以上便是我对于人类学习和AI学习的一点点思考。</p>
<p>The above is a little bit of my thinking about human learning and AI learning.</p>
]]></content>
      <tags>
        <tag>Brainstorm</tag>
      </tags>
  </entry>
  <entry>
    <title>AI version “Mining” system for AIGC: Take stable diffusion image generation model as a example</title>
    <url>/2024/03/12/AI-version-%E2%80%9CMining%E2%80%9D-system-for-AIGC-Take-stable-diffusion-image-generation-model-as-a-example/</url>
    <content><![CDATA[<h1 id="AI-version-“Mining”-system-for-AIGC-Take-stable-diffusion-image-generation-model-as-a-example"><a href="#AI-version-“Mining”-system-for-AIGC-Take-stable-diffusion-image-generation-model-as-a-example" class="headerlink" title="AI version “Mining” system for AIGC: Take stable diffusion image generation model as a example"></a>AI version “Mining” system for AIGC: Take stable diffusion image generation model as a example</h1><p>英文来自于Notion 机器翻译</p>
<p>介于现在AIGC模型的兴起，如果我们要生成一张图片，一些人在计算机算力上是非常缺失的，而另一些人却拥有非常多的计算机算力。此外，AI应用中，70%左右的算力都应用在了推演中。所以我在想，是否可以设计一个类似于以太币挖矿。我们可以用数字货币购买gas，而购买gas约等于购买算力和存储空间，然后我们便可以用gas部署我们的AI智能合约(Smart contract)。</p>
<p>With the rise of AIGC models, if we want to generate an image, some people are very lacking in computer computing power, while others have a lot of computer computing power. Moreover, in AI applications, about 70% of the computing power is applied in inference. So I’m wondering if we could design something similar to Ethereum mining. We can buy gas with cryptocurrency, and purchasing gas is approximately equivalent to buying computing power and storage space. Then we can use the gas to deploy our AI smart contracts.</p>
<p>由于运行合约的时候，模型可能会被拆分到各台机器中运行，而可被拆分的模型是一个新兴的研究方向，如 <a href="https://arxiv.org/abs/2212.13345">Forward-Forward Algorithm</a>和我的<a href="https://ieeexplore.ieee.org/document/10332073">DFF: Distributed Forward-Forward Algorithm</a>论文。目前研究的并不是很完善。因此，我们在这里将 stable diffusion model中的steps作为被分割的对象。即，我们将每一个step分割到各个机器中运行，如下图：</p>
<p>When running contracts, the model may be split into different machines for operation, and a model that can be split is a new research direction, such as the <strong><a href="https://arxiv.org/abs/2212.13345">Forward-Forward Algorithm</a></strong> and my <strong><a href="https://ieeexplore.ieee.org/document/10332073">DFF: Distributed Forward-Forward Algorithm</a></strong> paper. The current research is not complete. Therefore, we will use the steps in the stable diffusion model as the split objects here. That is, we will split each step into different machines for operation, as shown in the figure below:</p>
<p><img src="/images/ai_miner.drawio.png" alt="ai_miner.drawio.png"></p>
<p>想在完成这套系统主要存在的问题有：（以后还会补充）</p>
<ol>
<li>如何将通用的问题切割成小问题？</li>
<li>如果是要训练模型，训练的时候数据集又怎么处理？</li>
<li>每一个Node中如何评价是否“挖到”了我们希望得到的模型结果？</li>
<li>如何backpropagation？需要backpropagation吗？</li>
<li>如何解决并发的问题，如何将模型设计成并发推演或训练的？</li>
</ol>
<p>The main problems that exist in completing this system are: (will be supplemented later)</p>
<ol>
<li>How to split general problems into smaller problems?</li>
<li>If it is to train the model, how to handle the dataset during training?</li>
<li>How to evaluate in each Node whether we have “mined” the model results we hope to get?</li>
<li>How to backpropagate? Is backpropagation needed?</li>
<li>How to solve concurrency issues, and how to design the model for concurrent inference or training?</li>
</ol>
]]></content>
      <tags>
        <tag>Brainstorm</tag>
      </tags>
  </entry>
  <entry>
    <title>关于各被制裁行业的统一标准的制定——“统一规范制定联盟”成立的必要性</title>
    <url>/2024/03/17/%E5%85%B3%E4%BA%8E%E5%90%84%E8%A2%AB%E5%88%B6%E8%A3%81%E8%A1%8C%E4%B8%9A%E7%9A%84%E7%BB%9F%E4%B8%80%E6%A0%87%E5%87%86%E7%9A%84%E5%88%B6%E5%AE%9A%E2%80%94%E2%80%94%E2%80%9C%E7%BB%9F%E4%B8%80%E8%A7%84%E8%8C%83%E5%88%B6%E5%AE%9A%E8%81%94%E7%9B%9F%E2%80%9D%E6%88%90%E7%AB%8B%E7%9A%84%E5%BF%85%E8%A6%81%E6%80%A7/</url>
    <content><![CDATA[<p>由于我们近百年来的落后发展和来自西方资本为主的国际社会的排斥，虽然我们在最近几十年几代人的拼命努力，我们终于在大部分领域追到了世界前列的水平。</p>
<p>但是，由于大部分行业和领域都起始于西方社会，我们为了迎合国际市场，不得不遵守西方定制的统一规范标准，这在我看来是非常危险的一件事情。诚然，全世界如果都能在同一行业使用同一套标准来生产产品可以使得各企业之间的产品拥有更好的互利互通性，但是，却无法避免的存在非常多的不确定性,比如：</p>
<ol>
<li><strong>无法保证规范标准没有利好偏向</strong>：以我的经验来看，大部分西方定制的标准都存在一定的利好偏向的。几大行业寡头，为了定制有利于自己产品生产的规范，会联合起来定制一些并没有那么符合实际的规范标准。</li>
<li><strong>无法保证某些标准不存在专利寡头</strong>：由于有些标准确立初始只有某些特定的企业有于其匹配的专利产品，一旦这种标准被确定，几乎就等于所有企业都得购买特定企业的专利才能进行生产，这种标准也是非常的不合理的。</li>
<li><strong>无法保证国家制裁导致的标准制裁</strong>：在某些情况下，由于被制裁，我们甚至无法被允许和国际社会使用同一套标准，因为标准中往往会出现第2点中提到的专利寡头。</li>
</ol>
<p>因此，基于现在的严峻形式，我觉得我们各行各业的同胞们，应该定制我们自己的规范联盟，凡防于为来。</p>
<p>其实，关于标准定制竞争的成功案例，我们其实已经有了很多先例，比如银联与visa，master之争，华为的5G规范之争，但是，我仍然认为，这些规范的定义仍然是在西方集团框架之下的抵抗。但是我在反思，为什么我们不能跳出西方框架，自己走一条自己的路呢？我们的产品远销全世界，我们的产品质量也是最好的，我们有自己的技术，自己的销售渠道，为什么要听他人的标准呢？我们各行业的企业家们,为什么不可以按照自己的标准来生产产品呢? 为什么我们不能成立一个像IEEE那像的行业标准定制联盟呢？</p>
<p>我认为，基于国情，我们的行业标准定制联盟，不能完全模仿西方世界的方法。我们应该发展我们自己特色的行业定制联盟。以下是我的几点想法：</p>
<ol>
<li><strong>踩着别人的肩膀过河</strong>：如题，我们白手起家，完全重新定义一些标准也是不现实的，我们完全可以模仿他人已经定制好的标准，再经过一定的改进，定制自己的标准。特别是某一些行业，别人都不带我们玩了，我们也没必要客气，没必要有什么契约精神和道德规范，就是模仿之后再定制我们自己的规范就好，踩着别人的肩膀过河，站在“巨人”的肩膀做事嘛。</li>
<li><strong>做新型领域开拓者</strong>：对于成熟的行业，我们可以“踩着别人的肩膀过河”，而对于新兴的行业，我们应该有自己的行业自行，直接定制自己的行业规范和标准。特别是AI，芯片和操作系统这些领域，我们必须自己定制自己的标准，大家一起集中力量做大做强，这些领域急需整个行业的人一起努力来摆脱制裁。</li>
<li><strong>各企业团结起来</strong>：我们既然要定自己的标准规范，自然也要有人去定制和遵守，这点上我呼吁各行业各企业之间摈弃以往因为竞争带来的嫌隙，理解唇亡齿寒的道理。大企业带头，大家团结一致，一起定制符合行业持续发展的标准和规范。</li>
<li><strong>前置专利共享</strong>：定制标注和规范，不可避免的存在一些前置专利的问题，我认为，我们企业之间要是能大方免费或者低价共享这些前置专利的话，那将是百利无害的。毕竟没有市场的专利是无法转换为利益的。</li>
<li><strong>政府参与控制</strong>：我认为企业以逐利为唯一目的是无可厚非的，但是我们不能忽视了消费者和国家人民的利益，政府的适量参与和干预还是非常有必要的。至于为什么不能直接由政府直接定制规范，毕竟专业的事让专业的人做可能会更加合适。</li>
</ol>
<p>总的来说，我在这里是呼吁各行各业的企业们团结起来，我们一起成立一个“统一规范制定联盟”，大家一起定制我们自己的行业标准，一起避免被外部势力卡脖子的现象发生。拿操作系统举例，近几年国内操作系统发展迅猛，但是各个企业之间也各自为营，做着自己标准的事情，这非此不利于操作系统上层的软件生态的开发，各企业之间若是能开诚布公，共享自己的专利，规范和标准，不重复造车，集中力量做好一套标准系统，软件开发者一次代码构建，便可应用在各个操作系统中，将会大大吸引广大开发者的开发热忱。</p>
<p>以上都是我的一些胡言乱语，疯狂头脑风暴，在内行人看来可能非常不现实甚至是搞笑。读者要是看了觉得有道理，可以联系我，大家一起深入探讨构建更好的蓝图，要是觉得是个笑话，就请您全当是个笑话，一笑而过吧。</p>
]]></content>
      <tags>
        <tag>Idle talk</tag>
      </tags>
  </entry>
  <entry>
    <title>My Little Projects</title>
    <url>/2024/03/17/My-Little-Projects/</url>
    <content><![CDATA[<p><a href="https://dengbuqi.github.io/life_counter/"><strong>Life Goal Counter</strong></a><br><a href="https://dengbuqi.github.io/life_counter/"><img src="/images/life_counter.png" alt="life_counter"></a></p>
<p><a href="https://dengbuqi.github.io/bookofanswers/"><strong>Book of Answers</strong></a><br><a href="https://dengbuqi.github.io/bookofanswers/"><img src="/images/bookofanswers.png" alt="bookofanswers"></a></p>
<p><a href="https://dengbuqi.github.io/cell_yolov8-seg-tfjs/"><strong>Cell Segmentation Application Using YOLOv8</strong></a><br><a href="https://dengbuqi.github.io/cell_yolov8-seg-tfjs/"><img src="/images/cell_yolov8-seg.png" alt="cell_yolov8-seg"></a></p>
<p><a href="https://dengbuqi.github.io/cell_yolov8-tfjs/"><strong>Cell Detection Application Using YOLOv8</strong></a><br><a href="https://dengbuqi.github.io/cell_yolov8-tfjs/"><img src="/images/cell_yolov8-det.png" alt="cell_yolov8-det"></a></p>
<p><a href="https://dengbuqi.github.io/Combat-Effectiveness-Detection_yolov8-tfjs/"><strong>Combat Effectiveness Detection using YOLOv8 and Tensorflow.js</strong></a><br><a href="https://dengbuqi.github.io/Combat-Effectiveness-Detection_yolov8-tfjs/"><img src="/images/ce.jpg" alt="CE_Det"></a></p>
<p><a href="https://dengbuqi.github.io/heartbeat-js-FaceAPI/"><strong>Heartbeat-Estimation</strong></a><br><a href="https://dengbuqi.github.io/heartbeat-js-FaceAPI/"><img src="/images/heartbeat.jpg" alt="HB_Det"></a></p>
]]></content>
      <tags>
        <tag>Project</tag>
      </tags>
  </entry>
</search>
